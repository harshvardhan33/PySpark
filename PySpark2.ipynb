{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75c6597f",
   "metadata": {},
   "source": [
    "# Pyspark Important Functionalities \n",
    "1. Pyspark DataFrame \n",
    "2. Reading the data \n",
    "3. Check Data Types\n",
    "4. Select columns and indexing\n",
    "5. Check Schema\n",
    "6. Adding Columns \n",
    "7. Dropping Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df90c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229088a4",
   "metadata": {},
   "source": [
    "## Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7629951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://HarshVardhan:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataFrame</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f7f9730550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"DataFrame\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6acdbf",
   "metadata": {},
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12a20dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header',True).csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50584ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
      "|age|sex| cp|trestbps|chol|fbs|restecg|thalach|exang|oldpeak|slope| ca|thal|target|\n",
      "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
      "| 63|  1|  3|     145| 233|  1|      0|    150|    0|    2.3|    0|  0|   1|     1|\n",
      "| 37|  1|  2|     130| 250|  0|      1|    187|    0|    3.5|    0|  0|   2|     1|\n",
      "| 41|  0|  1|     130| 204|  0|      0|    172|    0|    1.4|    2|  0|   2|     1|\n",
      "| 56|  1|  1|     120| 236|  0|      1|    178|    0|    0.8|    2|  0|   2|     1|\n",
      "| 57|  0|  0|     120| 354|  0|      1|    163|    1|    0.6|    2|  0|   2|     1|\n",
      "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4100e5",
   "metadata": {},
   "source": [
    "Each value in the below schema is showing as the String type but actually there are values which are integer, so why in schema we are having other datatype? By default pyspark infers each value as string, we need to set the **inferSchema = True.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "737752b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- cp: string (nullable = true)\n",
      " |-- trestbps: string (nullable = true)\n",
      " |-- chol: string (nullable = true)\n",
      " |-- fbs: string (nullable = true)\n",
      " |-- restecg: string (nullable = true)\n",
      " |-- thalach: string (nullable = true)\n",
      " |-- exang: string (nullable = true)\n",
      " |-- oldpeak: string (nullable = true)\n",
      " |-- slope: string (nullable = true)\n",
      " |-- ca: string (nullable = true)\n",
      " |-- thal: string (nullable = true)\n",
      " |-- target: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the schema of the dataset \n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d98fba",
   "metadata": {},
   "source": [
    " Keeping the **inferSchema = True** to get the actual datatypes in the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36db557d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sex: integer (nullable = true)\n",
      " |-- cp: integer (nullable = true)\n",
      " |-- trestbps: integer (nullable = true)\n",
      " |-- chol: integer (nullable = true)\n",
      " |-- fbs: integer (nullable = true)\n",
      " |-- restecg: integer (nullable = true)\n",
      " |-- thalach: integer (nullable = true)\n",
      " |-- exang: integer (nullable = true)\n",
      " |-- oldpeak: double (nullable = true)\n",
      " |-- slope: integer (nullable = true)\n",
      " |-- ca: integer (nullable = true)\n",
      " |-- thal: integer (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.option('header',True).csv(\"heart.csv\", inferSchema=True)\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83b9e958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sex: integer (nullable = true)\n",
      " |-- cp: integer (nullable = true)\n",
      " |-- trestbps: integer (nullable = true)\n",
      " |-- chol: integer (nullable = true)\n",
      " |-- fbs: integer (nullable = true)\n",
      " |-- restecg: integer (nullable = true)\n",
      " |-- thalach: integer (nullable = true)\n",
      " |-- exang: integer (nullable = true)\n",
      " |-- oldpeak: double (nullable = true)\n",
      " |-- slope: integer (nullable = true)\n",
      " |-- ca: integer (nullable = true)\n",
      " |-- thal: integer (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# you can include the header=True and everything in the csv column\n",
    "df_pyspark = spark.read.csv(\"heart.csv\",header=True,inferSchema=True)\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c15361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_pyspark))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c6e8b",
   "metadata": {},
   "source": [
    "## Columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d578a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'sex',\n",
       " 'cp',\n",
       " 'trestbps',\n",
       " 'chol',\n",
       " 'fbs',\n",
       " 'restecg',\n",
       " 'thalach',\n",
       " 'exang',\n",
       " 'oldpeak',\n",
       " 'slope',\n",
       " 'ca',\n",
       " 'thal',\n",
       " 'target']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e44959f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=63, sex=1, cp=3, trestbps=145, chol=233, fbs=1, restecg=0, thalach=150, exang=0, oldpeak=2.3, slope=0, ca=0, thal=1, target=1),\n",
       " Row(age=37, sex=1, cp=2, trestbps=130, chol=250, fbs=0, restecg=1, thalach=187, exang=0, oldpeak=3.5, slope=0, ca=0, thal=2, target=1),\n",
       " Row(age=41, sex=0, cp=1, trestbps=130, chol=204, fbs=0, restecg=0, thalach=172, exang=0, oldpeak=1.4, slope=2, ca=0, thal=2, target=1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c5d24",
   "metadata": {},
   "source": [
    "## Select a pyspark column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "707df2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 63|\n",
      "| 37|\n",
      "| 41|\n",
      "| 56|\n",
      "| 57|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(\"age\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6eb97b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|age|sex|\n",
      "+---+---+\n",
      "| 63|  1|\n",
      "| 37|  1|\n",
      "| 41|  0|\n",
      "| 56|  1|\n",
      "| 57|  0|\n",
      "+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select([\"age\",\"sex\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dd27c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('sex', 'int'),\n",
       " ('cp', 'int'),\n",
       " ('trestbps', 'int'),\n",
       " ('chol', 'int'),\n",
       " ('fbs', 'int'),\n",
       " ('restecg', 'int'),\n",
       " ('thalach', 'int'),\n",
       " ('exang', 'int'),\n",
       " ('oldpeak', 'double'),\n",
       " ('slope', 'int'),\n",
       " ('ca', 'int'),\n",
       " ('thal', 'int'),\n",
       " ('target', 'int')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcc8cf4",
   "metadata": {},
   "source": [
    "## Add and Drop Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69714a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumn(\"Age after 2 years \",df_pyspark[\"Age\"]+2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4c98363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'sex',\n",
       " 'cp',\n",
       " 'trestbps',\n",
       " 'chol',\n",
       " 'fbs',\n",
       " 'restecg',\n",
       " 'thalach',\n",
       " 'exang',\n",
       " 'oldpeak',\n",
       " 'slope',\n",
       " 'ca',\n",
       " 'thal',\n",
       " 'target',\n",
       " 'Age after 2 years ']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66cc55b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|Age after 2 years |\n",
      "+------------------+\n",
      "|                65|\n",
      "|                39|\n",
      "|                43|\n",
      "|                58|\n",
      "|                59|\n",
      "|                59|\n",
      "|                58|\n",
      "|                46|\n",
      "|                54|\n",
      "|                59|\n",
      "|                56|\n",
      "|                50|\n",
      "|                51|\n",
      "|                66|\n",
      "|                60|\n",
      "|                52|\n",
      "|                60|\n",
      "|                68|\n",
      "|                45|\n",
      "|                71|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(\"Age after 2 years \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20f138ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.drop(\"Age after 2 years \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18ee5ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'sex',\n",
       " 'cp',\n",
       " 'trestbps',\n",
       " 'chol',\n",
       " 'fbs',\n",
       " 'restecg',\n",
       " 'thalach',\n",
       " 'exang',\n",
       " 'oldpeak',\n",
       " 'slope',\n",
       " 'ca',\n",
       " 'thal',\n",
       " 'target']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c8d848",
   "metadata": {},
   "source": [
    "## Renaming a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b389be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumnRenamed(\"Age\",\"Meri Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e90cf11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Meri Age',\n",
       " 'sex',\n",
       " 'cp',\n",
       " 'trestbps',\n",
       " 'chol',\n",
       " 'fbs',\n",
       " 'restecg',\n",
       " 'thalach',\n",
       " 'exang',\n",
       " 'oldpeak',\n",
       " 'slope',\n",
       " 'ca',\n",
       " 'thal',\n",
       " 'target']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9973d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Meri Age|\n",
      "+--------+\n",
      "|      63|\n",
      "|      37|\n",
      "|      41|\n",
      "|      56|\n",
      "|      57|\n",
      "|      57|\n",
      "|      56|\n",
      "|      44|\n",
      "|      52|\n",
      "|      57|\n",
      "|      54|\n",
      "|      48|\n",
      "|      49|\n",
      "|      64|\n",
      "|      58|\n",
      "|      50|\n",
      "|      58|\n",
      "|      66|\n",
      "|      43|\n",
      "|      69|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(\"Meri Age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b33729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
